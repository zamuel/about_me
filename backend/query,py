import os
import openai
import cortex
from dotenv import load_dotenv

load_dotenv()

# API keys
openai.api_key = os.getenv("OPENAI_API_KEY")
cortex.configure(
    api_key=os.getenv("CORTEX_API_KEY"),
    environment=os.getenv("CORTEX_ENVIRONMENT"),
    organization=os.getenv("CORTEX_ORG")
)
DATASET = os.getenv("CORTEX_DATASET", "recruiter-profile")

def generate_embedding(text: str) -> list[float]:
    response = openai.Embedding.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response["data"][0]["embedding"]

def query_cortex(user_question: str, top_k: int = 5) -> list[str]:
    vector = generate_embedding(user_question)
    index = cortex.Index(DATASET)

    results = index.query(
        vector=vector,
        top_k=top_k,
        include_metadata=True
    )

    documents = [r["text"] for r in results["matches"]]
    return documents

def generate_answer(user_question: str, context_docs: list[str]) -> str:
    context = "\n\n".join(context_docs)

    prompt = f"""You are a helpful assistant helping a recruiter learn about a candidate.
Context:
{context}

Question:
{user_question}

Answer:"""

    response = openai.ChatCompletion.create(
        model="gpt-4",  # or "gpt-3.5-turbo"
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response["choices"][0]["message"]["content"]

if __name__ == "__main__":
    question = input("Ask about the candidate: ")
    docs = query_cortex(question)
    answer = generate_answer(question, docs)
    print(f"\nAnswer:\n{answer}")
